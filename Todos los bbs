import sympy as sp
import math
import numpy as np
from sympy.utilities.lambdify import lambdify
from scipy.optimize import minimize_scalar
from sympy import lambdify
from scipy.optimize import minimize

#funciones basicas-----------------------------------------------------------------

def fibonacci(n):
    fib_sequence = [0, 1]
    while len(fib_sequence) < n:
        next_fib = fib_sequence[-1] + fib_sequence[-2]
        fib_sequence.append(next_fib)
    return fib_sequence[-1]

#escribir funcion
def f1(x):
    return retornar la funcion a evaluar
def f2(x):
    return  x[i] 

def gradiante (f, p):
    num = len(p)
    variabls = []
    evaluar = []
    for i in range (num):
      indice = i+1
      variable = 'x' + str(indice)
      variabls.append(variable)
      evaluar.append(sp.diff(f,variable))
    gra = []
    for j in evaluar:
        gra.append(eval(str(j), vars(math), {variabls[i]: p[i] for i in range(num)}))
    return gra

def evaluar_vec (f, vec, variables):
  for var in range(len(variables)):
    f = f.replace(variables[var], f'({vec[var]})')
  return f

def hessian_matriz(f,p):
    num = len(p)
    variabls = []
    evaluar = []
    for i in range (num):
      evaluar.append([])
      indice = i+1
      variable = 'x' + str(indice)
      variabls.append(variable)
      fprima = sp.diff(f,variable)
      indicemenor = 1
      for x in range(num):
        variablemenor = 'x' + str(indicemenor)
        evaluar[i].append(sp.diff(fprima, variablemenor))
        indicemenor += 1
    h =[]
    k = 0
    for fun in evaluar:
      h.append([])
      for i in fun:
        h[k].append(eval(str(i), vars(math), {variabls[j]: p[j] for j in range(num)}))
      k +=1
    return h

def lambda_newton_cg (g, d, h):
      uno = []
      for i in range(len(g)):
        g[i] = (-1)*g[i]
      uno = np.dot(g,d)
      dos = np.dot(h,d)
      tres = np.dot(dos, d)
      l = uno / tres
      return l

def beta_newton_cg (g, d, h):
  uno = np.dot(h, d)
  dos = np.dot(g,uno)
  tres = np.dot(d,uno)
  return dos/tres
#---------------------------------------------------------------------------------------
#----------------------------------------Métodos una variable---------------------------
#---------------------------------------------------------------------------------------

#---------------Método de busqueda sección dorada----------------
def busqueda_seccion_dorada(func, a, b, h):
    alfa = (math.sqrt(5) - 1) / 2
    landa = a + (1-alfa)*(b-a)
    miu = a + alfa * (b-a)
    flanda = abs(eval(str(func), vars(math), {'a':landa}))
    fmiu = abs(eval(str(func), vars(math), {'a':miu}))
    while b-a > h:
        if flanda > fmiu:
            #paso 2
            ak = flanda
            bk = b
            #paso 4
            landak = ak + (1 - alfa)*(bk - ak)
            miuk = ak + alfa*(bk - ak)
            flanda = func(landak)
            fmiu = func(miuk)
            a = ak
            b = bk
            landa = landak
            miu = miuk

        if flanda <= fmiu:
            #paso 3
            ak = a
            bk = miu
            #paso 4
            landak = ak + (1 - alfa)*(bk - ak)
            miuk = ak + alfa*(bk - ak)
            flanda = abs(eval(str(func), vars(math), {'a':landak}))
            fmiu = abs(eval(str(func), vars(math), {'a':miuk}))
            a = ak
            b = bk
            landa = landak
            miu = miuk
        return (a + b)/2

#--------------- Método de busqueda de Fibonacci----------------
def busqueda_fibonacci (f, a, b, h, e):
    n = 2
    fibo = fibonacci(n)
    while fibo < ((b-a)/h):
        n += 1
        fibo = fibonacci(n)
    fmenos = fibonacci(n-1)
    landa = a + (1 - (fmenos/fibo))*(b - a)
    print(landa)
    miu = a + (fmenos/fibo)*(b - a)
    flanda = f(landa)
    print(flanda)
    fmiu = f(miu)
    #paso principal
    for k in range(n):
        #paso 1
        if flanda>fmiu:
            #paso 2
            ak = landa
            bk = b
        else:
            ak = a
            bk = miu
        #paso 4
        landak = ak + (1 - (fibonacci(n-k-1)/ fibonacci(n - k))) * (bk - ak)
        miuk = ak + (fibonacci(n-k-1)/fibonacci(n - k)) * (bk - ak)
        if k == (n - 2):
            #paso 5
            landan = landak
            miun = landan + e
            flandan = f(landan)
            fmiun = f(miun)
            if flandan > fmiun:
                an = landan
                bn = bk
                return (an + bn)/2
            if flanda <= fmiun:
                an = ak
                bn =miun
                return (an + bn)/2
            #acaba paso 5
        else:
            a = ak
            b = bk 
            landa = landak
            miu = miuk
            flanda = f(landa)
            fmiu =  f(miu)

#--------------- Método de busqueda de bisección----------------
def busqueda_biseccion(f, a, b, h):
    fprima = sp.diff(f,'x')
    while b-a > h:
        #paso 1
        landa = (a+b)/2
        fpl = eval(str(fprima), vars(math), {'x':landa})
        #paso 2
        if fpl == 0:
            return landa
        elif fpl > 0:
            ak = a
            bk = landa
        elif fpl < 0 :
            ak = landa
            bk = b
        a = ak
        b = bk
    return (a+b)//2
#--------------- Método de Newton----------------
def metodo_newton (f, landa, h, e):
    fprima = sp.diff(f,'x')
    fsprima = sp.diff(fprima, 'x')
    #paso 1
    fpl = abs(eval(str(fprima), vars(math), {'x':landa}))
    while fpl > e:
        fspl = eval(str(fsprima), vars(math), {'x':landa})
        landak = landa - (fpl / fspl)
        #paso 2
        if abs(landak - landa) <e:
            return landak
        else:
            landa = landak
            fpl = abs(eval(str(fprima), vars(math), {'x':landa}))
    return landa  

#---------------------------------------------------------------------------------------
#----------------------------------------Métodos varias variables---------------------------
#---------------------------------------------------------------------------------------

#------------------- Método de Newton para varias variables------------------
def metodo_newton_bi (f, x1, e):
    x = x1
    gra = gradiante(f, x)
    variabls = len (gra)
    norma = 0
    for i in range(len(gra)):
        norma = norma + gra[i]**2
    norma = math.sqrt(norma)
    #paso principal
    while norma > e:
      hessian = hessian_matriz (f, x)
      if np.linalg.det (hessian) == 0:
        return 'La matriz Hessian no tiene inversa'
      else:
        hessian_inver = np.linalg.inv(np.array(hessian))
      resultado = np.dot(hessian_inver,gra)
      xk = np.array(x) - np.array(resultado)
      #paso 2
      vec = np.array(xk) - np.array(x)
      norma2 = 0
      for i in range(len(gra)):
        norma2 = norma2 + vec[i]**2
        if norma2 < 0 :
          return xk
      norma2 = math.sqrt(norma)
      if norma2 < e:
        return xk
      else:
        x = xk
        gra = gradiante(f, x)
        variabls = len (gra)
        norma = 0
        for i in range(len(gra)):
          norma = norma + gra[i]**2
        norma = math.sqrt(norma)
    return x

#--------------------- Método del descenso más empinado-------------------
def descenso_empinado(f, x1, e):
    num = len(x1)
    gra = gradiante(f, x1)
    norma = 0
    x = x1
    for i in range(len(gra)):
      norma = norma + gra[i]**2
    norma = math.sqrt(norma)
    while norma > e:
        d = [n*(-1) for n in gra]
        evaluar = []
        for n in range(num):
          evaluar.append(str(x[n])+'+a*' +'('+str(d[n])+')')
        variabls = ['x'+str(i+1) for i in range(num)]
        op = evaluar_vec(f, evaluar, variabls)
        f_f = lambdify('a', op)
        landa = minimize_scalar(f_f, method='brent').x
        xk = []
        for i in range(len(gra)):
          xk.append(x[i] + landa*d[i])
        x = xk
        norma = 0
        gra = gradiante(f, x)
        for i in range(len(gra)):
          norma = norma + gra[i]**2
        norma = math.sqrt(norma)
    return x

#------------------- Método de Newton cg--------------------------------
def newton_cg (f, x1, e):
    x = x1
    nvariables = len(x1)
    gra = gradiante(f, x1)
    norma = 0
    x = x1
    for i in range(len(gra)):
      norma = norma + gra[i]**2
    norma = math.sqrt(norma)
    while norma > e:
      g = gra
      d = [g0*(-1) for g0 in gra]
      hessian = hessian_matriz (f, x)
      landa = lambda_newton_cg(g, d, hessian)
      xk = []
      for n in range(nvariables):    
        #paso a
        for i in range(len(gra)):
            xk.append(x[i] + landa*d[i])
        #paso b
        gk = gradiante(f,xk)
        #paso c
        beta = beta_newton_cg(g, d, hessian)
        #comienza a cambiar variables
        dk = [g0*(-1)+beta for g0 in gk]
        x = xk
        g = gk
        d = dk
        hessian = hessian_matriz(f,x)
        landa = lambda_newton_cg(g, d, hessian)
        xk = []
      #evaluando para paso 1
      gra = gradiante(f, x)
      norma = 0
      for i in range(len(gra)):
        norma = norma + gra[i]**2
      norma = math.sqrt(norma)
    return x

#-------------------- Método de Nelder y Mead -----------------------
def nelder_mead(func, x1, e, max_iter=1000):
    n = len(x1)
    vertices = [x1]
    for i in range(n):
        x = x1.copy()
        x[i] += 1.0
        vertices.append(x)
    for i in range(max_iter):
        vertices.sort(key=lambda x: func(x))
        best = vertices[0]
        worst = vertices[-1]
        centroid = np.mean(vertices[:-1], axis=0)
        reflection = centroid + (centroid - worst)
        if func(reflection) < func(worst):
            expansion = centroid + 2.0 * (reflection - centroid)
            if func(expansion) < func(reflection):
                vertices[-1] = expansion
            else:
                vertices[-1] = reflection
        else:
            contraction = centroid + 0.5 * (worst - centroid)
            if func(contraction) < func(worst):
                vertices[-1] = contraction
            else:
                for i in range(1, n+1):
                    vertices[i] = 0.5 * (vertices[i] + best)
        if np.linalg.norm(vertices[0] - vertices[-1]) < e:
            break
    return vertices[0]
